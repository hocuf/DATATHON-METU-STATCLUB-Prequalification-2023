{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782cbde2",
   "metadata": {},
   "source": [
    "# DATATHON@METUSTATCLUB Prequalification 2023!\n",
    "\n",
    "### INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a794b",
   "metadata": {},
   "source": [
    "In this datathon project you will be given an 18-month transaction dataset. You will start by dividing this dataset into 2 separate 9-month periods. You will create a churn model using the first 9-month period.\n",
    "\n",
    "In the second step, you will create a churn variable. The first 9-month period will be used for this process. For example, users who were active in the first 6-month period will be identified and it will be determined whether these users churned in the last 3-month period. If there is a response imbalance, this problem should be solved before model creation.\n",
    "\n",
    "Finally, using what you have learnt from the first 9-month period, you will use your churn model to predict whether the active customers in the dataset in the second 9-month period (for example, those active in the first 6 months of the second dataset) will churn in the last 3 months.\n",
    "\n",
    "This project focuses on analysing the transaction dataset and predicting the probability of customer churn. Steps such as processing this data, building a model and interpreting the results are necessary to analyse the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93cb5a",
   "metadata": {},
   "source": [
    "#### STEPS:\n",
    "- Read the documentation describing the dataset and the notes about the dataset.\n",
    "- Load the dataset and examine the dataset to analyse the data.\n",
    "- Analyse the size, columns, number of missing data and other statistical properties of the data set.\n",
    "- Divide the data set into two separate 9-month periods.\n",
    "- Churn variable is created. In the creation of this variable, users who are active in the first 6 months of the first 9-month period will be determined and it is determined whether churn has been performed in the last 3 months.\n",
    "- Appropriate techniques are applied if necessary to solve the imbalance of the churn variable.\n",
    "- Select an appropriate algorithm to create a churn model and train this model using it in the first 9-month period.\n",
    "- Test the created churn model and evaluate its performance.\n",
    "- Load the dataset in the second 9-month period and using the model, estimate the probability that users who were active in the first 6-month period will churn in the last 3 months.\n",
    "- Test your predictions and evaluate the model performance\n",
    "- Results are visualised and interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac750f4",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded284c",
   "metadata": {},
   "source": [
    "### The libraries to be used are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aed81f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Clsassification Models\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "        # Deep Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "        # Testing\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "        # Standart Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c0548",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb9ab9",
   "metadata": {},
   "source": [
    "### Separated as Sales, Products, Customers. Separated excel files are read as DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d81eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_excel(\"sales23.xlsx\")\n",
    "customers = pd.read_excel(\"customers23.xlsx\")\n",
    "products = pd.read_excel(\"products23.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07536b9",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9d4d0",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Analysis\n",
    "\n",
    "- It is the process of understanding, exploring, and visualizing data. In this process, we will clean the data, characterize and perform statistical analysis, visualize the data and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a27f020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>500546547</td>\n",
       "      <td>2017-01-01 01:40:39.180</td>\n",
       "      <td>10334</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Cash</td>\n",
       "      <td>51.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID     UserID                DateTime  ProductID Channel  \\\n",
       "0              1  500546547 2017-01-01 01:40:39.180      10334  MOBILE   \n",
       "\n",
       "  PaymentType  Price Discount  \n",
       "0        Cash   51.0       No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12895001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>Female Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID      Category\n",
       "0      10001  Female Shoes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbd5588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserFirstTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500234532</td>\n",
       "      <td>2011-10-12</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ANTALYA</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID UserFirstTransaction  Gender Location  Age\n",
       "0  500234532           2011-10-12  FEMALE  ANTALYA   19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbdda7",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753d29a",
   "metadata": {},
   "source": [
    "### Based on the common UserID column in the Sales and Customers column, the ones we merge are merged with the ProductID column common to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e9f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>UserFirstTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>500546547</td>\n",
       "      <td>2017-01-01 01:40:39.180</td>\n",
       "      <td>10334</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Cash</td>\n",
       "      <td>51.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ANKARA</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID     UserID                DateTime  ProductID Channel  \\\n",
       "0              1  500546547 2017-01-01 01:40:39.180      10334  MOBILE   \n",
       "\n",
       "  PaymentType  Price Discount UserFirstTransaction  Gender Location  Age  \n",
       "0        Cash   51.0       No           2015-03-18  FEMALE   ANKARA   30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(sales, customers, on='UserID')\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed1420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>UserFirstTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>500546547</td>\n",
       "      <td>2017-01-01 01:40:39.180</td>\n",
       "      <td>10334</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Cash</td>\n",
       "      <td>51.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ANKARA</td>\n",
       "      <td>30</td>\n",
       "      <td>Female Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID     UserID                DateTime  ProductID Channel  \\\n",
       "0              1  500546547 2017-01-01 01:40:39.180      10334  MOBILE   \n",
       "\n",
       "  PaymentType  Price Discount UserFirstTransaction  Gender Location  Age  \\\n",
       "0        Cash   51.0       No           2015-03-18  FEMALE   ANKARA   30   \n",
       "\n",
       "       Category  \n",
       "0  Female Shoes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(merged_df, products, on='ProductID')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec13ee",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5da98e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionID', 'UserID', 'DateTime', 'ProductID', 'Channel',\n",
       "       'PaymentType', 'Price', 'Discount', 'UserFirstTransaction', 'Gender',\n",
       "       'Location', 'Age', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7ba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2039021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MOBILE', 'WEB'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Channel\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf8bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cash', 'Mobile Payment', 'Online Credit Card'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PaymentType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0848c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51.   ,  21.   ,  30.   , ...,  34.425, 258.6  , 400.65 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Price\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99634182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Discount\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e273ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FEMALE', 'MALE'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51ae5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANKARA', 'TRABZON', 'ESKISEHIR', 'KAYSERI', 'IZMIR', 'ANTALYA',\n",
       "       'ISTANBUL', 'BURSA', 'ADANA'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Location\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9adb345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 28, 26, 41, 34, 43, 38, 31, 36, 32, 44, 33, 39, 21, 29, 23, 49,\n",
       "       40, 22, 37, 48, 46, 50, 24, 19, 20, 27, 25, 35, 47, 42, 45],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Age\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa83c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female Shoes', 'Female Fashion', 'Sport Shoes', 'Smart Phones',\n",
       "       'Electronic Accessories', 'Kitchen Electronics',\n",
       "       'Computers & Laptops', 'TVs and TV Sets', 'Male Shoes',\n",
       "       'Outdoor Sports', 'Hobbies', 'Male Fashion', 'Sound Systems',\n",
       "       'Smart Watches', 'Indoor Sports'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2afe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69059 entries, 0 to 69058\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   TransactionID         69059 non-null  int64         \n",
      " 1   UserID                69059 non-null  int64         \n",
      " 2   DateTime              69059 non-null  datetime64[ns]\n",
      " 3   ProductID             69059 non-null  int64         \n",
      " 4   Channel               69059 non-null  object        \n",
      " 5   PaymentType           69059 non-null  object        \n",
      " 6   Price                 69059 non-null  float64       \n",
      " 7   Discount              69059 non-null  object        \n",
      " 8   UserFirstTransaction  69059 non-null  datetime64[ns]\n",
      " 9   Gender                69059 non-null  object        \n",
      " 10  Location              69059 non-null  object        \n",
      " 11  Age                   69059 non-null  int64         \n",
      " 12  Category              69059 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(4), object(6)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcbf847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID           0\n",
       "UserID                  0\n",
       "DateTime                0\n",
       "ProductID               0\n",
       "Channel                 0\n",
       "PaymentType             0\n",
       "Price                   0\n",
       "Discount                0\n",
       "UserFirstTransaction    0\n",
       "Gender                  0\n",
       "Location                0\n",
       "Age                     0\n",
       "Category                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc408182",
   "metadata": {},
   "source": [
    " - There are no columns with empty content. No filling is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097dabbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008126</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.042132</td>\n",
       "      <td>-0.009846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <td>-0.008126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007742</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>0.052687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductID</th>\n",
       "      <td>0.009950</td>\n",
       "      <td>-0.007742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012901</td>\n",
       "      <td>0.012371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>0.042132</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>-0.012901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.009846</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.061357</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TransactionID    UserID  ProductID     Price       Age\n",
       "TransactionID       1.000000 -0.008126   0.009950  0.042132 -0.009846\n",
       "UserID             -0.008126  1.000000  -0.007742 -0.004037  0.052687\n",
       "ProductID           0.009950 -0.007742   1.000000 -0.012901  0.012371\n",
       "Price               0.042132 -0.004037  -0.012901  1.000000  0.061357\n",
       "Age                -0.009846  0.052687   0.012371  0.061357  1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132681c",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- It is the process of creating new features using existing features in the data set. In this process, existing features \tare manipulated or combined to make the data more meaningful, improve model performance and achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "397a04f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Discount\"]= df[\"Discount\"].map({'No':0,'Yes':1})\n",
    "df[\"Discount\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e05ccd",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf3155",
   "metadata": {},
   "source": [
    "### All given data were analysed. It was made ready for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d023f",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f7216",
   "metadata": {},
   "source": [
    "# Question 1: You are given an 18-month transactional data set. Please split this data set into two 9-month periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7437126",
   "metadata": {},
   "source": [
    "To divide the 18-month transaction dataset into two 9-month periods, you can follow the steps below:\n",
    "\n",
    "- Determine the time range of the dataset by identifying the smallest and largest dates in the dataset.\n",
    "- Add 9 months to the smallest date to determine the first 9-month period. This will be the cut-off date for the first period.\n",
    "- For the first period, filter the transactions from the smallest date to the cut-off date\n",
    "- For the second period, the transactions from the cut-off date to the largest date are filtered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30ee08",
   "metadata": {},
   "source": [
    "#### Read the dataset and get the '**DateTime**' column in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "898883db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f279c",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643bebc",
   "metadata": {},
   "source": [
    "#### The smallest and largest dates in the dataset are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d8063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df['DateTime'].min()\n",
    "max_date = df['DateTime'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601de30",
   "metadata": {},
   "source": [
    "- Find the minimum (**min_date**) and maximum (**max_date**) dates in the dataset. This step determines the time range of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf740edf",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cf324",
   "metadata": {},
   "source": [
    "#### To determine the first 9-month period, 9 months are added to the smallest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59498573",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date_9_months = min_date + pd.DateOffset(months=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044858e",
   "metadata": {},
   "source": [
    "- The cutoff date between two periods is determined by adding 9 months to the smallest date (**cutoff_date_9_months**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fbf7e",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990c36e",
   "metadata": {},
   "source": [
    "#### For the first period, the transactions from the smallest date to the cut-off date are filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19d947ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_period = df[df['DateTime'] <= cutoff_date_9_months]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fbcd07",
   "metadata": {},
   "source": [
    "- A DataFrame named '**first_period**' is created containing all transactions up to the cut-off date. This DataFrame represents the first 9 months of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267eeb6c",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2cc99d",
   "metadata": {},
   "source": [
    "#### For the second period, filter the transactions from the cut-off date to the largest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9eaee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_period = df[df['DateTime'] > cutoff_date_9_months]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dcf5fd",
   "metadata": {},
   "source": [
    "- A DataFrame named '**second_period**' is created containing all transactions after the interrupt date. This DataFrame represents the second 9-month period of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724006",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21a183",
   "metadata": {},
   "source": [
    "#### First and second semester data sets are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c49325af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>UserFirstTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>500546547</td>\n",
       "      <td>2017-01-01 01:40:39.180</td>\n",
       "      <td>10334</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Cash</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ANKARA</td>\n",
       "      <td>30</td>\n",
       "      <td>Female Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID     UserID                DateTime  ProductID Channel  \\\n",
       "0              1  500546547 2017-01-01 01:40:39.180      10334  MOBILE   \n",
       "\n",
       "  PaymentType  Price  Discount UserFirstTransaction  Gender Location  Age  \\\n",
       "0        Cash   51.0         0           2015-03-18  FEMALE   ANKARA   30   \n",
       "\n",
       "       Category  \n",
       "0  Female Shoes  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_period.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b995734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>UserFirstTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33462</td>\n",
       "      <td>500338383</td>\n",
       "      <td>2017-11-05 15:09:01.390</td>\n",
       "      <td>10334</td>\n",
       "      <td>WEB</td>\n",
       "      <td>Mobile Payment</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>TRABZON</td>\n",
       "      <td>28</td>\n",
       "      <td>Female Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID     UserID                DateTime  ProductID Channel  \\\n",
       "3          33462  500338383 2017-11-05 15:09:01.390      10334     WEB   \n",
       "\n",
       "      PaymentType  Price  Discount UserFirstTransaction  Gender Location  Age  \\\n",
       "3  Mobile Payment   30.0         0           2014-06-19  FEMALE  TRABZON   28   \n",
       "\n",
       "       Category  \n",
       "3  Female Shoes  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_period.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f4d03",
   "metadata": {},
   "source": [
    "- By printing the first five lines of the two newly created DataFrames (**first_period** and **second_period**), we check that they are correctly divided into periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0216dd5",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418e23c",
   "metadata": {},
   "source": [
    "**The above code splits the 18-month transaction dataset into two 9-month periods and stores these periods in two separate DataFrames. These steps can be used to use the dataset for purposes such as time series analysis or to study customer behaviour over different periods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b192a5",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe798f3f",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95079698",
   "metadata": {},
   "source": [
    "# Question 2: Create churn variable from dataset. You are supposed to use the first 9-month duration to construct your model. For example, you should use the first 6-month duration for the active users and use the last 3-month period to determine if these active users churn within this 3-month period. (Please resolve if there is imbalance in response before modeling.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ddff9",
   "metadata": {},
   "source": [
    "This question asks you to create a \"churn\" variable from an existing dataset. Churn refers to when a customer stops using a service or product. The question asks you to use the first 9 months in the dataset to build your model.\n",
    "\n",
    "Let's explain the steps as follows:\n",
    "\n",
    "- Using the 'DateTime' column in the dataset, determine that the data is over a period of 9 months. You will use the first 6 months to identify active users, while the last 3 months are used to determine whether these users churn or not.\n",
    "\n",
    "- Determine the users who were active during the first 6 months. To do this, make sure that each user (UserID) has made at least one transaction during this period. A list of these users is created.\n",
    "\n",
    "- In the last 3-month period, the previously determined active users are checked for churn. If there are no transactions from a user in this period, this user can be considered as churn.\n",
    "\n",
    "- Churn values are added to the dataset as a new 'Churn' column. This column will contain the values 0 (no churn) or 1 (churn) for each user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880aa50f",
   "metadata": {},
   "source": [
    "#### Read the dataset and get the date columns in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ebdb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df['UserFirstTransaction'] = pd.to_datetime(df['UserFirstTransaction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10498f8",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a775fd",
   "metadata": {},
   "source": [
    "#### The first 6 months and the last 3 months are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10f74fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date_6_months = df['DateTime'].min() + pd.DateOffset(months=6)\n",
    "cutoff_date_9_months = df['DateTime'].min() + pd.DateOffset(months=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e866f",
   "metadata": {},
   "source": [
    " - For the first 6 months, a cut-off date is set by adding 6 months to the minimum date. Likewise, another cut-off date is set for the 9-month period by adding 9 months to the minimum date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e248d26",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1466c",
   "metadata": {},
   "source": [
    "#### Active users in the first 6 months are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58558768",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users = df[df['DateTime'] <= cutoff_date_6_months]['UserID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecdca5f",
   "metadata": {},
   "source": [
    "- It takes a unique list of users who have made transactions within the first 6 months and assigns it to a list called \"**active_users**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f764632",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d46fb2",
   "metadata": {},
   "source": [
    "#### For active users, it is checked whether they have made transactions in the last 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bd62556",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_users = []\n",
    "for user in active_users:\n",
    "    user_transactions = df[df['UserID'] == user]\n",
    "    last_transaction = user_transactions['DateTime'].max()\n",
    "    if last_transaction <= cutoff_date_6_months:\n",
    "        churn_users.append(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca162d0f",
   "metadata": {},
   "source": [
    "- In the list of active users, we start the loop and retrieve the transactions of each user. If the user's last transaction date is less than or equal to the 6 month cut-off date, this user is added to the \"**churn_users**\" list. This means that the user has not processed in the last 3 months and is considered churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6d421",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3320d4",
   "metadata": {},
   "source": [
    "#### The Churn column is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ed3a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = np.where(df['UserID'].isin(churn_users), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba1429",
   "metadata": {},
   "source": [
    "- A new column called \"**Churn**\" is created. If the user is in the churn_users list, we assign the value 1 to this column; if not, we assign the value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e490518",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4e4c0",
   "metadata": {},
   "source": [
    "#### The state of imbalance is checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9261da10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    67346\n",
      "1     1713\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "churn_counts = df['Churn'].value_counts()\n",
    "print(churn_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e1783",
   "metadata": {},
   "source": [
    "- This situation indicates a class imbalance. That is, the proportion of users with churn is considerably lower than the proportion of users without churn. An imbalanced dataset means that your prediction model will tend to accurately predict non-churn users, but may struggle to predict churn users well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542dcad",
   "metadata": {},
   "source": [
    "## To address this imbalance, we use **Oversampling** to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d66d0",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique) is used to stabilise the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af78769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Churn','TransactionID','UserID','DateTime','ProductID','UserFirstTransaction'],axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd5143",
   "metadata": {},
   "source": [
    "- Churn, TransactionID, UserID, DateTime, ProductID, UserFirstTransaction columns have been deleted. Because date data and target column are deleted when making classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acade1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc9f67",
   "metadata": {},
   "source": [
    "- The remaining object columns do not contain values that are superior to each other. With the **get_dummies()** method, it is turned into a matrix without establishing dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb8c9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e364b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    53882\n",
       "1    53882\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea380fbd",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f404f5e",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6490b",
   "metadata": {},
   "source": [
    "## Question 3: Once you learn from the first 9-month period, proceed with the second 9-month data. Use your churn model obtained in (2) to predict if active customers (for example, those who were active in the first 6-month period of the second data set) churn in the last 3 months of this duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594a958",
   "metadata": {},
   "source": [
    "This question asks us to predict whether customers in the second 9-month period will churn, using the churn pattern learnt in the first 9-month period. For this purpose, the following steps are followed.\n",
    "\n",
    "- Identify the active users in the second 9-month period\n",
    "- Train the churn model (using the dataset previously balanced with SMOTE).\n",
    "- For active users it is predicted whether they will churn or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65300dfc",
   "metadata": {},
   "source": [
    "#### A period of 6 months and a period of 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0162f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_window = pd.DateOffset(months=6)\n",
    "churn_time_window = pd.DateOffset(months=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6f642",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c23798",
   "metadata": {},
   "source": [
    "#### First 6 months of the second term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adfa2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_period_active_start = cutoff_date_9_months\n",
    "second_period_active_end = second_period_active_start + active_time_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3455f0",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44790f91",
   "metadata": {},
   "source": [
    "#### Last 3 months in the second semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f71097",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_period_churn_start = second_period_active_end\n",
    "second_period_churn_end = second_period_churn_start + churn_time_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4746e4",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98341f03",
   "metadata": {},
   "source": [
    "#### Active users in the second period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "416b9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_second_period = second_period[(second_period['DateTime'] >= second_period_active_start) & (second_period['DateTime'] <= second_period_active_end)]['UserID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c101c6",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21040e4f",
   "metadata": {},
   "source": [
    "**In order to determine the best method, a method was created that trains and tests several important classification methods at once and freezes the Accuracy, F1 and Recall scores in a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85ac39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_test(x,y):\n",
    "    gauss = GaussianNB()\n",
    "    kneClas = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    bernoulli = BernoulliNB()\n",
    "    randForestClas= RandomForestClassifier()\n",
    "    gradBoodClas = GradientBoostingClassifier()\n",
    "    logReg = LogisticRegression()\n",
    "    decTreeClas = DecisionTreeClassifier()\n",
    "    xboost = XGBClassifier()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "    \n",
    "    algos = [gauss,kneClas,svc,bernoulli,randForestClas,gradBoodClas,logReg,decTreeClas,xboost]\n",
    "    algo_names = [\"GaussianNB\",\"KNeighborsClassifier\",\"SVC\",\"BernoulliNB\",\"RandomForestClassifier\",\"GradientBoostingClassifier\",\"LogisticRegression\",\"DecisionTreeClassifier\",\"XGBClassifier\"]\n",
    "    ac_sc = []\n",
    "    f1_sc = []\n",
    "    rec_sc = []\n",
    "    \n",
    "    result = pd.DataFrame(columns = [\"Accuracy_Score\",\"F1_Score\",\"Recall_Score\"],index = algo_names)\n",
    "    \n",
    "    for algo in algos:\n",
    "        algo.fit(x_train_resampled,y_train_resampled)\n",
    "        ac_sc.append(accuracy_score(algo.predict(x_test),y_test))\n",
    "        f1_sc.append(f1_score(algo.predict(x_test),y_test))\n",
    "        rec_sc.append(recall_score(algo.predict(x_test),y_test))\n",
    "        \n",
    "    result.Accuracy_Score =ac_sc\n",
    "    result.F1_Score = f1_sc\n",
    "    result.Recall_Score = rec_sc\n",
    "    return result.sort_values(\"Accuracy_Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99cdd93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Recall_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.977483</td>\n",
       "      <td>0.464716</td>\n",
       "      <td>0.579399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.965175</td>\n",
       "      <td>0.405439</td>\n",
       "      <td>0.355748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.957573</td>\n",
       "      <td>0.334091</td>\n",
       "      <td>0.276316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.890892</td>\n",
       "      <td>0.128398</td>\n",
       "      <td>0.080377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.057814</td>\n",
       "      <td>0.034298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.839632</td>\n",
       "      <td>0.151666</td>\n",
       "      <td>0.087494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.814871</td>\n",
       "      <td>0.059581</td>\n",
       "      <td>0.034163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.782942</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.040887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.366783</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.027353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy_Score  F1_Score  Recall_Score\n",
       "RandomForestClassifier            0.977483  0.464716      0.579399\n",
       "DecisionTreeClassifier            0.965175  0.405439      0.355748\n",
       "XGBClassifier                     0.957573  0.334091      0.276316\n",
       "GradientBoostingClassifier        0.890892  0.128398      0.080377\n",
       "LogisticRegression                0.848972  0.057814      0.034298\n",
       "KNeighborsClassifier              0.839632  0.151666      0.087494\n",
       "BernoulliNB                       0.814871  0.059581      0.034163\n",
       "SVC                               0.782942  0.072975      0.040887\n",
       "GaussianNB                        0.366783  0.052643      0.027353"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x,y) # Using method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7e770",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbdd48",
   "metadata": {},
   "source": [
    "## Since RandomForestClassifier() gives the best result, we choose it for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e48525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444627dd",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0c64c",
   "metadata": {},
   "source": [
    "#### Determine the property columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8396c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'TransactionID', 'DateTime', 'ProductID', 'Channel', 'PaymentType',\n",
    "    'Price', 'Discount', 'UserFirstTransaction', 'Gender', 'Location',\n",
    "    'Age', 'Category'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baa273",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336dbbb",
   "metadata": {},
   "source": [
    "#### The properties are filtered for active users in the second semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d524d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users_raw = df[df['UserID'].isin(active_users_second_period)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449080a",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11661f2",
   "metadata": {},
   "source": [
    "#### Matrixing is applied according to the characteristics of active users in the second period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8aeeffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users = pd.get_dummies(x_active_users_raw[feature_columns], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca0a66",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050514ad",
   "metadata": {},
   "source": [
    "#### The column order is made the same as the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "616a28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users = x_active_users[x.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5a311",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db610e",
   "metadata": {},
   "source": [
    "#### Churn predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87a3ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_user_churn_predictions = model.predict(x_active_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933a522",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cc475",
   "metadata": {},
   "source": [
    "#### Forecasts for active users in the second period are added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d70b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users['Churn_Prediction'] = active_user_churn_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771fa6f",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b1245",
   "metadata": {},
   "source": [
    "#### UserIDs are added back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d13e46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users['UserID'] = x_active_users_raw['UserID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a376e0",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb0174",
   "metadata": {},
   "source": [
    "#### Churn forecasts are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2074a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Churn_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500546547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500546547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Churn_Prediction\n",
       "0  500546547                 0\n",
       "1  500546547                 0\n",
       "2  500338383                 0\n",
       "3  500338383                 0\n",
       "4  500338383                 0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = x_active_users[['UserID', 'Churn_Prediction']]\n",
    "k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe49d5d",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a795520",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25676ef4",
   "metadata": {},
   "source": [
    "## As Alternative - Deep Learning With Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc6c06e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "540/540 [==============================] - 15s 20ms/step - loss: 0.1372 - accuracy: 0.9665\n",
      "Epoch 2/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1201 - accuracy: 0.9752\n",
      "Epoch 3/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1163 - accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "540/540 [==============================] - 11s 19ms/step - loss: 0.1146 - accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1123 - accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1127 - accuracy: 0.9752\n",
      "Epoch 7/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.1114 - accuracy: 0.9752\n",
      "Epoch 8/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1104 - accuracy: 0.9752\n",
      "Epoch 9/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.1092 - accuracy: 0.9753\n",
      "Epoch 10/100\n",
      "540/540 [==============================] - 11s 19ms/step - loss: 0.1090 - accuracy: 0.9753\n",
      "Epoch 11/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.1082 - accuracy: 0.9753\n",
      "Epoch 12/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1075 - accuracy: 0.9754\n",
      "Epoch 13/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1071 - accuracy: 0.9753\n",
      "Epoch 14/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.1064 - accuracy: 0.9753\n",
      "Epoch 15/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1061 - accuracy: 0.9755\n",
      "Epoch 16/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1052 - accuracy: 0.9757\n",
      "Epoch 17/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.1043 - accuracy: 0.9759\n",
      "Epoch 18/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1038 - accuracy: 0.9760\n",
      "Epoch 19/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1035 - accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1027 - accuracy: 0.9758\n",
      "Epoch 21/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1026 - accuracy: 0.9759\n",
      "Epoch 22/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.1010 - accuracy: 0.9762\n",
      "Epoch 23/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1009 - accuracy: 0.9760\n",
      "Epoch 24/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.1003 - accuracy: 0.9762\n",
      "Epoch 25/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.1006 - accuracy: 0.9760\n",
      "Epoch 26/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0982 - accuracy: 0.9763\n",
      "Epoch 27/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0986 - accuracy: 0.9766\n",
      "Epoch 28/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0984 - accuracy: 0.9761\n",
      "Epoch 29/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0967 - accuracy: 0.9768\n",
      "Epoch 30/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0970 - accuracy: 0.9764\n",
      "Epoch 31/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0965 - accuracy: 0.9765\n",
      "Epoch 32/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0967 - accuracy: 0.9766\n",
      "Epoch 33/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0958 - accuracy: 0.9766\n",
      "Epoch 34/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0949 - accuracy: 0.9768\n",
      "Epoch 35/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0955 - accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0938 - accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0926 - accuracy: 0.9774\n",
      "Epoch 38/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0924 - accuracy: 0.9772\n",
      "Epoch 39/100\n",
      "540/540 [==============================] - 11s 19ms/step - loss: 0.0919 - accuracy: 0.9770\n",
      "Epoch 40/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0915 - accuracy: 0.9774\n",
      "Epoch 41/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0908 - accuracy: 0.9774\n",
      "Epoch 42/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0907 - accuracy: 0.9777\n",
      "Epoch 43/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0894 - accuracy: 0.9781\n",
      "Epoch 44/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0896 - accuracy: 0.9777\n",
      "Epoch 45/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0885 - accuracy: 0.9781\n",
      "Epoch 46/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0879 - accuracy: 0.9780\n",
      "Epoch 47/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0882 - accuracy: 0.9779\n",
      "Epoch 48/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0866 - accuracy: 0.9782\n",
      "Epoch 49/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0871 - accuracy: 0.9781\n",
      "Epoch 50/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0867 - accuracy: 0.9781\n",
      "Epoch 51/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0853 - accuracy: 0.9784\n",
      "Epoch 52/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0845 - accuracy: 0.9786\n",
      "Epoch 53/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0848 - accuracy: 0.9786\n",
      "Epoch 54/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0837 - accuracy: 0.9788\n",
      "Epoch 55/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0832 - accuracy: 0.9789\n",
      "Epoch 56/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0833 - accuracy: 0.9787\n",
      "Epoch 57/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0820 - accuracy: 0.9790\n",
      "Epoch 58/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0815 - accuracy: 0.9788\n",
      "Epoch 59/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0809 - accuracy: 0.9794\n",
      "Epoch 60/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0800 - accuracy: 0.9795\n",
      "Epoch 61/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0797 - accuracy: 0.9793\n",
      "Epoch 62/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0801 - accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0799 - accuracy: 0.9793\n",
      "Epoch 64/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0780 - accuracy: 0.9796\n",
      "Epoch 65/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0780 - accuracy: 0.9795\n",
      "Epoch 66/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0766 - accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0773 - accuracy: 0.9795\n",
      "Epoch 68/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0760 - accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0757 - accuracy: 0.9797\n",
      "Epoch 70/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0752 - accuracy: 0.9801\n",
      "Epoch 71/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0738 - accuracy: 0.9802\n",
      "Epoch 72/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0730 - accuracy: 0.9803\n",
      "Epoch 73/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0737 - accuracy: 0.9801\n",
      "Epoch 74/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0733 - accuracy: 0.9801\n",
      "Epoch 75/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0719 - accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0717 - accuracy: 0.9804\n",
      "Epoch 77/100\n",
      "540/540 [==============================] - 12s 21ms/step - loss: 0.0722 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0701 - accuracy: 0.9805\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0694 - accuracy: 0.9808\n",
      "Epoch 80/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0701 - accuracy: 0.9808\n",
      "Epoch 81/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0687 - accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0689 - accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0674 - accuracy: 0.9812\n",
      "Epoch 84/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0685 - accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0669 - accuracy: 0.9812\n",
      "Epoch 86/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0666 - accuracy: 0.9810\n",
      "Epoch 87/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0657 - accuracy: 0.9812\n",
      "Epoch 88/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0653 - accuracy: 0.9816\n",
      "Epoch 89/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0653 - accuracy: 0.9813\n",
      "Epoch 90/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0651 - accuracy: 0.9811\n",
      "Epoch 91/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0634 - accuracy: 0.9817\n",
      "Epoch 92/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0660 - accuracy: 0.9814\n",
      "Epoch 93/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0635 - accuracy: 0.9817\n",
      "Epoch 94/100\n",
      "540/540 [==============================] - 11s 21ms/step - loss: 0.0628 - accuracy: 0.9818\n",
      "Epoch 95/100\n",
      "540/540 [==============================] - 11s 20ms/step - loss: 0.0625 - accuracy: 0.9819\n",
      "Epoch 96/100\n",
      "540/540 [==============================] - 10s 19ms/step - loss: 0.0626 - accuracy: 0.9817\n",
      "Epoch 97/100\n",
      "540/540 [==============================] - 10s 18ms/step - loss: 0.0615 - accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "540/540 [==============================] - 9s 18ms/step - loss: 0.0608 - accuracy: 0.9819\n",
      "Epoch 99/100\n",
      "540/540 [==============================] - 10s 18ms/step - loss: 0.0679 - accuracy: 0.9807\n",
      "Epoch 100/100\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 0.0616 - accuracy: 0.9818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1e2e83370>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dense(8, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\" ,metrics=\"accuracy\")\n",
    "model.fit(x,y, epochs=100, batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bb913c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 1024)              30720     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 730,753\n",
      "Trainable params: 730,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfaefd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159/2159 [==============================] - 12s 5ms/step - loss: 0.0571 - accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.057105787098407745, 0.9830290079116821]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9d319",
   "metadata": {},
   "source": [
    "## The success rate in modelling with Deep Learning, which we used as an alternative, was 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357b797",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332c43a",
   "metadata": {},
   "source": [
    "#### Scaling properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2f7f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x_active_users_scaled = scaler.transform(x_active_users[x.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46433ae1",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a280e4",
   "metadata": {},
   "source": [
    "#### Churn predictions are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b618c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_user_churn_predictions_dl = model.predict(x_active_users_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20d352",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e770ed4",
   "metadata": {},
   "source": [
    "#### Predictions are converted into binary classification results (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4fa1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_user_churn_predictions_dl_binary = (active_user_churn_predictions_dl > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c7ff8",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230b172",
   "metadata": {},
   "source": [
    "#### Forecasts for active users in the second period are added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99c02d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_active_users['Churn_Prediction_DL'] = active_user_churn_predictions_dl_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0489e7",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06467f68",
   "metadata": {},
   "source": [
    "####  Churn predictions are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd5be455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Churn_Prediction_DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500546547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500546547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500338383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Churn_Prediction_DL\n",
       "0  500546547                    0\n",
       "1  500546547                    0\n",
       "2  500338383                    0\n",
       "3  500338383                    0\n",
       "4  500338383                    0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_active_users[['UserID', 'Churn_Prediction_DL']]\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b5233",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e97c34",
   "metadata": {},
   "source": [
    "# CONCLUSIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d96b96",
   "metadata": {},
   "source": [
    "In this project, we performed a customer churn analysis using 18 months of transactional data from a company. The main objective of this analysis was to predict customer churn and thus optimise the company's customer relationship management strategies.\n",
    "\n",
    "The dataset contained different attributes such as transaction ID, user ID, date, product ID, payment channel and type, price, discount, user's first transaction date, gender, age and category. As a first step, we created the churn variable from the dataset. In this process, we determined whether active users in the first 9-month period churned in the following 3-month period.\n",
    "\n",
    "After constructing the churn variable, we addressed the problem of unbalanced class distribution. To solve this problem, we used the SMOTE method, thus removing the imbalance between churn and non-churn instances in the training dataset.\n",
    "\n",
    "Then, we split the dataset into two 9-month periods and use the churn model in the first period to predict whether active customers in the second period churn or not. These predictions can help the company to develop strategies to prevent customer churn.\n",
    "\n",
    "In the last step, we evaluated the performance of different classification algorithms on the SMOTE-balanced dataset, including Gaussian Naive Bayes, K-Nearest Neighbour, Support Vector Machines, Bernoulli Naive Bayes, Random Forest, Gradient Boosting, Logistic Regression and Decision Trees. By comparing the performances of these algorithms, the most appropriate model can be selected to enable the company to perform churn predictions more accurately and reliably.\n",
    "\n",
    "As a result of this project, by analysing customer churn and addressing the problem of unbalanced dataset, we have helped the company to predict customer churn. This information will help the business to improve customer relationship management strategies and take specific measures to prevent customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adecae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523742e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7d3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
